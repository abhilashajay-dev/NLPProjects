{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (1.25.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (8.1.6)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (6.8.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (1.24.3)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<10,>=7.1.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (4.24.0)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (12.0.1)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.18 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (13.5.2)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (4.7.1)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (4.3.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (0.21.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (3.1.32)\n",
      "Requirement already satisfied: pydeck<1,>=0.8 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (6.3.2)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.19.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.16.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.18->streamlit) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.18->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.18->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests<3,>=2.18->streamlit) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from tzlocal<5,>=1.1->streamlit) (0.1.0.post0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.9.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import spacy\n",
    "import streamlit as st\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Function to extract named entities (skills, experience, education, projects)\n",
    "def extract_entities(text):\n",
    "    lines = text.split('\\n')\n",
    "    skills = []\n",
    "    experience = []\n",
    "    education = []\n",
    "    projects = []\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(':')\n",
    "        if len(parts) == 2:\n",
    "            entity_type, entity_text = parts[0].strip(), parts[1].strip()\n",
    "            if entity_type == \"SKILL\":\n",
    "                skills.append(entity_text)\n",
    "            elif entity_type == \"EXPERIENCE\":\n",
    "                experience.append(entity_text)\n",
    "            elif entity_type == \"EDUCATION\":\n",
    "                education.append(entity_text)\n",
    "            elif entity_type == \"PROJECT\":\n",
    "                projects.append(entity_text)\n",
    "\n",
    "    return skills, experience, education, projects\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Resume Ranking App\")\n",
    "\n",
    "# User input for job description\n",
    "job_description = st.text_area(\"Enter the job description:\")\n",
    "\n",
    "# User input for resumes\n",
    "st.write(\"Enter the resumes in entity format. Use the following format:\")\n",
    "st.write(\"ENTITY_TYPE: ENTITY_TEXT\")\n",
    "st.write(\"Example:\")\n",
    "st.write(\"SKILL: Python, machine learning\\nEXPERIENCE: Worked on various projects, including a recommendation system.\\n\")\n",
    "resumes_text = st.text_area(\"Enter the resumes (one per line):\")\n",
    "\n",
    "if job_description and resumes_text:\n",
    "    # Combine the resumes and the job description into one list\n",
    "    resumes = resumes_text.strip().split('\\n')\n",
    "    all_text = resumes + [job_description]\n",
    "\n",
    "    # Create a CountVectorizer to convert text to a matrix of token counts\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(all_text)\n",
    "\n",
    "    # Calculate cosine similarity between the job description and all resumes\n",
    "    cosine_similarities = cosine_similarity(X[-1], X[:-1])\n",
    "\n",
    "    # Create a list of (resume, similarity score) pairs\n",
    "    resume_scores = list(zip(resumes, cosine_similarities[0]))\n",
    "\n",
    "    # Sort the resumes by similarity score in descending order\n",
    "    resume_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Display the ranked resumes with named entities\n",
    "    st.header(\"Ranked Resumes:\")\n",
    "    for i, (resume, score) in enumerate(resume_scores):\n",
    "        skills, experience, education, projects = extract_entities(resume)\n",
    "        st.subheader(f\"Rank {i + 1}: Similarity Score = {score:.4f}\")\n",
    "        st.write(\"Skills:\", \", \".join(skills))\n",
    "        st.write(\"Experience:\", \", \".join(experience))\n",
    "        st.write(\"Education:\", \", \".join(education))\n",
    "        st.write(\"Projects:\", \", \".join(projects))\n",
    "        st.write(\"Resume:\", resume)\n",
    "        st.write(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import streamlit as st\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Function to extract named entities (skills, experience, education, projects, and candidate name)\n",
    "def extract_entities(text):\n",
    "    lines = text.split('\\n')\n",
    "    skills = []\n",
    "    experience = []\n",
    "    education = []\n",
    "    projects = []\n",
    "    candidate_name = None\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(':')\n",
    "        if len(parts) == 2:\n",
    "            entity_type, entity_text = parts[0].strip(), parts[1].strip()\n",
    "            if entity_type == \"SKILL\":\n",
    "                skills.append(entity_text)\n",
    "            elif entity_type == \"EXPERIENCE\":\n",
    "                experience.append(entity_text)\n",
    "            elif entity_type == \"EDUCATION\":\n",
    "                education.append(entity_text)\n",
    "            elif entity_type == \"PROJECT\":\n",
    "                projects.append(entity_text)\n",
    "            elif entity_type == \"CANDIDATE_NAME\":\n",
    "                candidate_name = entity_text\n",
    "\n",
    "    return skills, experience, education, projects, candidate_name\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Resume Ranking App\")\n",
    "\n",
    "# User input for job description\n",
    "job_description = st.text_area(\"Enter the job description:\")\n",
    "\n",
    "# User input for resumes\n",
    "st.write(\"Enter the resumes in entity format. Use the following format:\")\n",
    "st.write(\"ENTITY_TYPE: ENTITY_TEXT\")\n",
    "st.write(\"Example:\")\n",
    "st.write(\"SKILL: Python, machine learning\\nEXPERIENCE: Developed machine learning models for sentiment analysis.\\nCANDIDATE_NAME: John Doe\\n\")\n",
    "resumes_text = st.text_area(\"Enter the resumes (one per line):\")\n",
    "\n",
    "if job_description and resumes_text:\n",
    "    # Combine the resumes and the job description into one list\n",
    "    resumes = resumes_text.strip().split('\\n')\n",
    "    all_text = resumes + [job_description]\n",
    "\n",
    "    # Create a CountVectorizer to convert text to a matrix of token counts\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(all_text)\n",
    "\n",
    "    # Calculate cosine similarity between the job description and all resumes\n",
    "    cosine_similarities = cosine_similarity(X[-1], X[:-1])\n",
    "\n",
    "    # Create a list of (resume, similarity score) pairs\n",
    "    resume_scores = list(zip(resumes, cosine_similarities[0]))\n",
    "\n",
    "    # Sort the resumes by similarity score in descending order\n",
    "    resume_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Display the ranked resumes with named entities, including candidate names\n",
    "    st.header(\"Ranked Resumes:\")\n",
    "    for i, (resume, score) in enumerate(resume_scores):\n",
    "        skills, experience, education, projects, candidate_name = extract_entities(resume)\n",
    "        st.subheader(f\"Rank {i + 1}: Similarity Score = {score:.4f}\")\n",
    "        st.write(\"Candidate Name:\", candidate_name)\n",
    "        st.write(\"Skills:\", \", \".join(skills))\n",
    "        st.write(\"Experience:\", \", \".join(experience))\n",
    "        st.write(\"Education:\", \", \".join(education))\n",
    "        st.write(\"Projects:\", \", \".join(projects))\n",
    "        st.write(\"Resume:\", resume)\n",
    "        st.write(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhilash\\AppData\\Local\\Temp\\ipykernel_6148\\2126252229.py:103: GradioDeprecationWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  iface = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import gradio as gr\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Function to extract named entities (skills, experience, education, projects, and candidate name)\n",
    "def extract_entities(text):\n",
    "    lines = text.split('\\n')\n",
    "    skills = []\n",
    "    experience = []\n",
    "    education = []\n",
    "    projects = []\n",
    "    candidate_name = None\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(':')\n",
    "        if len(parts) == 2:\n",
    "            entity_type, entity_text = parts[0].strip(), parts[1].strip()\n",
    "            if entity_type == \"SKILL\":\n",
    "                skills.append(entity_text)\n",
    "            elif entity_type == \"EXPERIENCE\":\n",
    "                experience.append(entity_text)\n",
    "            elif entity_type == \"EDUCATION\":\n",
    "                education.append(entity_text)\n",
    "            elif entity_type == \"PROJECT\":\n",
    "                projects.append(entity_text)\n",
    "            elif entity_type == \"CANDIDATE_NAME\":\n",
    "                candidate_name = entity_text\n",
    "\n",
    "    return skills, experience, education, projects, candidate_name\n",
    "\n",
    "# Function to calculate similarity\n",
    "def calculate_similarity(job_description, resume):\n",
    "    all_text = [job_description, resume]\n",
    "    \n",
    "    # Create a CountVectorizer to convert text to a matrix of token counts\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(all_text)\n",
    "    \n",
    "    # Calculate cosine similarity between the job description and the resume\n",
    "    cosine_similarities = cosine_similarity(X[0], X[1])\n",
    "\n",
    "    return cosine_similarities[0][0]\n",
    "\n",
    "# Function to generate dummy job description\n",
    "def generate_dummy_job_description():\n",
    "    fake = Faker()\n",
    "    job_title = fake.job()\n",
    "    job_description = fake.paragraphs(nb=2)\n",
    "    return f\"JOB_TITLE: {job_title}\\nJOB_DESCRIPTION: {' '.join(job_description)}\"\n",
    "\n",
    "# Function to generate dummy resumes\n",
    "def generate_dummy_resumes(num_resumes):\n",
    "    fake = Faker()\n",
    "    resumes = []\n",
    "\n",
    "    for _ in range(num_resumes):\n",
    "        candidate_name = fake.name()\n",
    "        skills = fake.words(nb=random.randint(3, 6))\n",
    "        experience = fake.paragraphs(nb=1)\n",
    "        education = fake.paragraphs(nb=1)\n",
    "        projects = fake.paragraphs(nb=1)\n",
    "        resume = f\"CANDIDATE_NAME: {candidate_name}\\nSKILLS: {', '.join(skills)}\\nEXPERIENCE: {' '.join(experience)}\\nEDUCATION: {' '.join(education)}\\nPROJECTS: {' '.join(projects)}\"\n",
    "        resumes.append(resume)\n",
    "\n",
    "    return resumes\n",
    "\n",
    "# Create Gradio interface\n",
    "def resume_ranking(job_description, *resumes):\n",
    "    results = []\n",
    "\n",
    "    for resume in resumes:\n",
    "        similarity_score = calculate_similarity(job_description, resume)\n",
    "        skills, experience, education, projects, candidate_name = extract_entities(resume)\n",
    "\n",
    "        results.append({\n",
    "            \"Candidate Name\": candidate_name,\n",
    "            \"Similarity Score\": similarity_score,\n",
    "            \"Skills\": skills,\n",
    "            \"Experience\": experience,\n",
    "            \"Education\": education,\n",
    "            \"Projects\": projects,\n",
    "            \"Resume\": resume\n",
    "        })\n",
    "\n",
    "    # Sort results by similarity score in descending order\n",
    "    results.sort(key=lambda x: x[\"Similarity Score\"], reverse=True)\n",
    "    \n",
    "    # Generate an HTML table for displaying results\n",
    "    html_table = \"<table><tr><th>Candidate Name</th><th>Similarity Score</th><th>Skills</th><th>Experience</th><th>Education</th><th>Projects</th><th>Resume</th></tr>\"\n",
    "    for result in results:\n",
    "        html_table += f\"<tr><td>{result['Candidate Name']}</td><td>{result['Similarity Score']:.4f}</td><td>{', '.join(result['Skills'])}</td><td>{', '.join(result['Experience'])}</td><td>{', '.join(result['Education'])}</td><td>{', '.join(result['Projects'])}</td><td>{result['Resume']}</td></tr>\"\n",
    "    html_table += \"</table>\"\n",
    "\n",
    "    return html_table\n",
    "\n",
    "# Define Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=resume_ranking,\n",
    "    inputs=[\"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\"],\n",
    "    outputs=gr.outputs.HTML(),\n",
    "    layout=\"vertical\",\n",
    "    title=\"Resume Ranking App\",\n",
    "    description=\"Enter the job description and up to 9 resumes in entity format. Use the following format:\\nENTITY_TYPE: ENTITY_TEXT\\nExample: SKILL: Python, machine learning\\nEXPERIENCE: Developed machine learning models for sentiment analysis.\\nCANDIDATE_NAME: John Doe\",\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<button onclick=\"generateRandomData()\">Generate Random Data</button>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhilash\\AppData\\Local\\Temp\\ipykernel_6148\\3274155016.py:113: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  job_description_input = gr.inputs.Textbox(label=\"Job Description\", default=generate_dummy_job_description())\n",
      "C:\\Users\\Abhilash\\AppData\\Local\\Temp\\ipykernel_6148\\3274155016.py:113: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  job_description_input = gr.inputs.Textbox(label=\"Job Description\", default=generate_dummy_job_description())\n",
      "C:\\Users\\Abhilash\\AppData\\Local\\Temp\\ipykernel_6148\\3274155016.py:113: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  job_description_input = gr.inputs.Textbox(label=\"Job Description\", default=generate_dummy_job_description())\n",
      "C:\\Users\\Abhilash\\AppData\\Local\\Temp\\ipykernel_6148\\3274155016.py:114: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  resume_inputs = [gr.inputs.Textbox(label=f\"Resume {i + 1}\", default=resume) for i, resume in enumerate(generate_dummy_resumes(9))]\n",
      "C:\\Users\\Abhilash\\AppData\\Local\\Temp\\ipykernel_6148\\3274155016.py:114: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  resume_inputs = [gr.inputs.Textbox(label=f\"Resume {i + 1}\", default=resume) for i, resume in enumerate(generate_dummy_resumes(9))]\n",
      "C:\\Users\\Abhilash\\AppData\\Local\\Temp\\ipykernel_6148\\3274155016.py:114: GradioDeprecationWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  resume_inputs = [gr.inputs.Textbox(label=f\"Resume {i + 1}\", default=resume) for i, resume in enumerate(generate_dummy_resumes(9))]\n",
      "C:\\Users\\Abhilash\\AppData\\Local\\Temp\\ipykernel_6148\\3274155016.py:117: GradioDeprecationWarning: `layout` parameter is deprecated, and it has no effect\n",
      "  iface = gr.Interface(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Function to extract named entities (skills, experience, education, projects, and candidate name)\n",
    "def extract_entities(text):\n",
    "    lines = text.split('\\n')\n",
    "    skills = []\n",
    "    experience = []\n",
    "    education = []\n",
    "    projects = []\n",
    "    candidate_name = None\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(':')\n",
    "        if len(parts) == 2:\n",
    "            entity_type, entity_text = parts[0].strip(), parts[1].strip()\n",
    "            if entity_type == \"SKILL\":\n",
    "                skills.append(entity_text)\n",
    "            elif entity_type == \"EXPERIENCE\":\n",
    "                experience.append(entity_text)\n",
    "            elif entity_type == \"EDUCATION\":\n",
    "                education.append(entity_text)\n",
    "            elif entity_type == \"PROJECT\":\n",
    "                projects.append(entity_text)\n",
    "            elif entity_type == \"CANDIDATE_NAME\":\n",
    "                candidate_name = entity_text\n",
    "\n",
    "    return skills, experience, education, projects, candidate_name\n",
    "\n",
    "# Function to calculate similarity\n",
    "def calculate_similarity(job_description, resume):\n",
    "    all_text = [job_description, resume]\n",
    "    \n",
    "    # Create a CountVectorizer to convert text to a matrix of token counts\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(all_text)\n",
    "    \n",
    "    # Calculate cosine similarity between the job description and the resume\n",
    "    cosine_similarities = cosine_similarity(X[0], X[1])\n",
    "\n",
    "    return cosine_similarities[0][0]\n",
    "\n",
    "# Function to generate dummy job description\n",
    "def generate_dummy_job_description():\n",
    "    fake = Faker()\n",
    "    job_title = fake.job()\n",
    "    job_description = fake.paragraphs(nb=2)\n",
    "    return f\"JOB_TITLE: {job_title}\\nJOB_DESCRIPTION: {' '.join(job_description)}\"\n",
    "\n",
    "# Function to generate dummy resumes\n",
    "def generate_dummy_resumes(num_resumes):\n",
    "    fake = Faker()\n",
    "    resumes = []\n",
    "\n",
    "    for _ in range(num_resumes):\n",
    "        candidate_name = fake.name()\n",
    "        skills = fake.words(nb=random.randint(3, 6))\n",
    "        experience = fake.paragraphs(nb=1)\n",
    "        education = fake.paragraphs(nb=1)\n",
    "        projects = fake.paragraphs(nb=1)\n",
    "        resume = f\"CANDIDATE_NAME: {candidate_name}\\nSKILLS: {', '.join(skills)}\\nEXPERIENCE: {' '.join(experience)}\\nEDUCATION: {' '.join(education)}\\nPROJECTS: {' '.join(projects)}\"\n",
    "        resumes.append(resume)\n",
    "\n",
    "    return resumes\n",
    "\n",
    "# Create an HTML button to generate random data\n",
    "button_html = \"\"\"\n",
    "<button onclick=\"generateRandomData()\">Generate Random Data</button>\n",
    "\"\"\"\n",
    "\n",
    "# JavaScript function to generate random data for job description and resumes\n",
    "javascript_code = \"\"\"\n",
    "function generateRandomData() {\n",
    "    // Generate random data for job description and resumes\n",
    "    var jobDescription = generateDummyJobDescription();\n",
    "    var resumes = generateDummyResumes(9);\n",
    "    \n",
    "    // Set the generated data in the input fields\n",
    "    document.getElementById('job-description').value = jobDescription;\n",
    "    for (var i = 0; i < resumes.length; i++) {\n",
    "        document.getElementById('resume-' + i).value = resumes[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "// Function to generate dummy job description\n",
    "function generateDummyJobDescription() {\n",
    "    // Implement the job description generation logic here\n",
    "    return \"Generated Job Description\";\n",
    "}\n",
    "\n",
    "// Function to generate dummy resumes\n",
    "function generateDummyResumes(numResumes) {\n",
    "    // Implement the resume generation logic here\n",
    "    var resumes = [];\n",
    "    for (var i = 0; i < numResumes; i++) {\n",
    "        resumes.push(\"Generated Resume \" + (i + 1));\n",
    "    }\n",
    "    return resumes;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Display the button and input fields\n",
    "display(HTML(button_html))\n",
    "\n",
    "# Create input fields for job description and resumes\n",
    "job_description_input = gr.inputs.Textbox(label=\"Job Description\", default=generate_dummy_job_description())\n",
    "resume_inputs = [gr.inputs.Textbox(label=f\"Resume {i + 1}\", default=resume) for i, resume in enumerate(generate_dummy_resumes(9))]\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=resume_ranking,\n",
    "    inputs=[job_description_input, *resume_inputs],\n",
    "    outputs=gr.outputs.HTML(),\n",
    "    layout=\"vertical\",\n",
    "    title=\"Resume Ranking App\",\n",
    "    description=\"Enter the job description and up to 9 resumes in entity format. Use the following format:\\nENTITY_TYPE: ENTITY_TEXT\\nExample: SKILL: Python, machine learning\\nEXPERIENCE: Developed machine learning models for sentiment analysis.\\nCANDIDATE_NAME: John Doe\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Descriptions:\n",
    "1. We are seeking a skilled data scientist with expertise in machine learning and natural language processing (NLP) to join our team. The ideal candidate should have experience working on text classification projects.\n",
    "\n",
    "2. We are looking for a web developer proficient in HTML, CSS, and JavaScript. The candidate should have experience building responsive and user-friendly web applications.\n",
    "\n",
    "3. We are hiring a project manager with a strong track record of leading cross-functional teams and delivering successful projects on time and within budget.\n",
    "\n",
    "4. We are seeking a software engineer with expertise in Python and data analysis. The ideal candidate should have experience working on big data projects.\n",
    "\n",
    "5. We are looking for a marketing manager with experience in digital marketing, social media, and email campaigns. The candidate should have a background in marketing strategy.\n",
    "\n",
    "6. We have an opening for a graphic designer who can create visually appealing designs for marketing materials. The candidate should be creative and detail-oriented.\n",
    "\n",
    "7. We are seeking an experienced financial analyst to join our finance team. The candidate should have a strong background in financial modeling and forecasting.\n",
    "\n",
    "8. We are looking for a customer support specialist to assist our customers with inquiries and issues. The candidate should have excellent communication skills.\n",
    "\n",
    "9. We have an opening for a data entry clerk to input and manage data in our database systems. The candidate should be organized and accurate in data entry.\n",
    "\n",
    "10. We are seeking a software quality assurance engineer to ensure the quality and reliability of our software products. The candidate should have experience in automated testing.\n",
    "\n",
    "11. We are looking for an experienced software architect to lead the design and development of our software solutions. The candidate should have a strong background in system design and architecture.\n",
    "\n",
    "12. We are seeking a data analyst with expertise in SQL and data visualization tools. The ideal candidate should be able to extract insights from large datasets.\n",
    "\n",
    "13. We have an opening for a network engineer to maintain and troubleshoot our network infrastructure. The candidate should have experience with Cisco networking equipment.\n",
    "\n",
    "14. We are looking for a content writer to create engaging and informative content for our blog and website. The candidate should have excellent writing and editing skills.\n",
    "\n",
    "15. We are hiring a sales representative to drive revenue growth for our company. The candidate should have a proven track record in sales and client relationship management.\n",
    "\n",
    "16. We are seeking a UX/UI designer to create user-friendly and visually appealing interfaces for our applications. The candidate should be skilled in design tools like Sketch and Figma.\n",
    "\n",
    "17. We have an opening for a healthcare professional to join our medical team. The candidate should have a medical degree and clinical experience.\n",
    "\n",
    "18. We are looking for a business analyst with expertise in data analysis and business process improvement. The candidate should be able to identify opportunities for optimization.\n",
    "\n",
    "19. We are hiring a software developer with a focus on mobile app development. The candidate should have experience with iOS and Android app development.\n",
    "\n",
    "20. We are seeking a human resources manager to oversee our HR operations. The candidate should have a strong background in HR policies and procedures.\n",
    "\n",
    "# Resumes (One Per Line):\n",
    "1. SKILL: Python, machine learning\n",
    "EXPERIENCE: Developed machine learning models for sentiment analysis.\n",
    "EDUCATION: Master's degree in Computer Science.\n",
    "CANDIDATE_NAME: John Smith\n",
    "\n",
    "2. SKILL: Web development, HTML, CSS, JavaScript\n",
    "EXPERIENCE: Built responsive web applications for various clients.\n",
    "EDUCATION: Bachelor's degree in Web Development.\n",
    "CANDIDATE_NAME: Jane Doe\n",
    "\n",
    "3. SKILL: Project management, team leadership\n",
    "EXPERIENCE: Managed a team of 15+ professionals on multiple projects.\n",
    "EDUCATION: MBA in Project Management.\n",
    "CANDIDATE_NAME: Robert Johnson\n",
    "\n",
    "4. SKILL: Python, data analysis, big data\n",
    "EXPERIENCE: Analyzed large datasets and contributed to data-driven decisions.\n",
    "EDUCATION: Bachelor's degree in Data Science.\n",
    "CANDIDATE_NAME: Sarah Williams\n",
    "\n",
    "5. SKILL: Digital marketing, social media, email campaigns\n",
    "EXPERIENCE: Led digital marketing efforts, increasing online presence.\n",
    "EDUCATION: Master's degree in Marketing.\n",
    "CANDIDATE_NAME: Michael Davis\n",
    "\n",
    "6. SKILL: Graphic design, Adobe Creative Suite\n",
    "EXPERIENCE: Created visually appealing marketing materials for clients.\n",
    "EDUCATION: Bachelor's degree in Graphic Design.\n",
    "CANDIDATE_NAME: Emily Brown\n",
    "\n",
    "7. SKILL: Financial modeling, forecasting\n",
    "EXPERIENCE: Prepared financial reports and forecasts for a Fortune 500 company.\n",
    "EDUCATION: Master's degree in Finance.\n",
    "CANDIDATE_NAME: Christopher Lee\n",
    "\n",
    "8. SKILL: Customer support, communication\n",
    "EXPERIENCE: Assisted customers with inquiries and resolved issues promptly.\n",
    "EDUCATION: Bachelor's degree in Business Administration.\n",
    "CANDIDATE_NAME: Amanda Wilson\n",
    "\n",
    "9. SKILL: Data entry, database management\n",
    "EXPERIENCE: Maintained accurate records in database systems.\n",
    "EDUCATION: High school diploma.\n",
    "CANDIDATE_NAME: Daniel Garcia\n",
    "\n",
    "10. SKILL: Quality assurance, automated testing\n",
    "EXPERIENCE: Ensured software quality through rigorous testing procedures.\n",
    "EDUCATION: Bachelor's degree in Computer Science.\n",
    "CANDIDATE_NAME: Olivia Martinez\n",
    "\n",
    "11. SKILL: Software architecture, system design\n",
    "EXPERIENCE: Led the design and development of complex software systems.\n",
    "EDUCATION: Master's degree in Computer Science.\n",
    "CANDIDATE_NAME: David Miller\n",
    "\n",
    "12. SKILL: Data analysis, SQL, data visualization\n",
    "EXPERIENCE: Extracted insights from large datasets to drive business decisions.\n",
    "EDUCATION: Bachelor's degree in Data Science.\n",
    "CANDIDATE_NAME: Jennifer Brown\n",
    "\n",
    "13. SKILL: Network maintenance, troubleshooting, Cisco equipment\n",
    "EXPERIENCE: Managed and maintained a large network infrastructure.\n",
    "EDUCATION: Cisco Certified Network Professional (CCNP).\n",
    "CANDIDATE_NAME: Michael Johnson\n",
    "\n",
    "14. SKILL: Content writing, editing\n",
    "EXPERIENCE: Created engaging content for blogs and websites.\n",
    "EDUCATION: Bachelor's degree in English.\n",
    "CANDIDATE_NAME: Sarah Anderson\n",
    "\n",
    "15. SKILL: Sales, client relationship management\n",
    "EXPERIENCE: Achieved consistent revenue growth through effective sales strategies.\n",
    "EDUCATION: Bachelor's degree in Business Administration.\n",
    "CANDIDATE_NAME: John Davis\n",
    "\n",
    "16. SKILL: UX/UI design, Sketch, Figma\n",
    "EXPERIENCE: Designed user-friendly interfaces for web and mobile applications.\n",
    "EDUCATION: Master's degree in Interaction Design.\n",
    "CANDIDATE_NAME: Emily Smith\n",
    "\n",
    "17. SKILL: Medical degree, clinical experience\n",
    "EXPERIENCE: Practiced medicine in various clinical settings.\n",
    "EDUCATION: Doctor of Medicine (MD).\n",
    "CANDIDATE_NAME: Dr. Robert Anderson\n",
    "\n",
    "18. SKILL: Business analysis, data analysis, process improvement\n",
    "EXPERIENCE: Identified process optimization opportunities, leading to cost savings.\n",
    "EDUCATION: MBA in Business Analytics.\n",
    "CANDIDATE_NAME: Jessica Wilson\n",
    "\n",
    "19. SKILL: Mobile app development, iOS, Android\n",
    "EXPERIENCE: Developed and launched mobile apps on iOS and Android platforms.\n",
    "EDUCATION: Bachelor's degree in Computer Engineering.\n",
    "CANDIDATE_NAME: Andrew Martinez\n",
    "\n",
    "20. SKILL: Human resources management, HR policies\n",
    "EXPERIENCE: Oversaw HR operations for a large organization.\n",
    "EDUCATION: Master's degree in Human Resources.\n",
    "CANDIDATE_NAME: Megan Johnson\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
