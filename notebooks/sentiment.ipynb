{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sentiment-analysis-on-movie-reviews/train.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=[\"SentenceId\"], inplace=True, keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Description\n",
    "The dataset is comprised of tab-separated files with phrases from the Rotten Tomatoes dataset. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Sentiment'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGrCAYAAADeuK1yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiHklEQVR4nO3dfVSUdf7/8dcAAiIOhAoDJ4RujiKVpFiIq2ZKopFpsZVlaa1pGnYy1Ird0r5uu7jWalaWdVzTWl2tTrmmRhKGeAzvaBGzNHM1bHXAO0BIUeH6/dHP2abQFQOHDzwf58w5zlyfueY9XnvyuTPXzNgsy7IEAABgEC9PDwAAAFBfBAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjOPj6QEaS21trQ4cOKC2bdvKZrN5ehwAAHABLMvS8ePHFRERIS+vc7/O0mwD5sCBA4qMjPT0GAAA4CLs379fl19++Tm3N9uAadu2raQf/wLsdruHpwEAABeioqJCkZGRrn/Hz6XZBszZt43sdjsBAwCAYf7X6R+cxAsAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDg+nh7AdNFPr/L0CL/avhkpnh4BAIB64RUYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcH08PADSU6KdXeXqEX23fjBRPjwAARuAVGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGKdeAZOZmakbbrhBbdu2VWhoqIYNG6Zdu3a5rTl58qTS0tLUrl07BQYGKjU1VSUlJW5riouLlZKSooCAAIWGhmrKlCk6c+aM25rc3Fx1795dfn5+uvrqq7Vw4cKLe4YAAKDZqVfArFu3Tmlpadq4caOys7N1+vRpDRw4UFVVVa41TzzxhD766CO99957WrdunQ4cOKA777zTtb2mpkYpKSk6deqUPv/8cy1atEgLFy7U1KlTXWv27t2rlJQU3XzzzSosLNTEiRP18MMP65NPPmmApwwAAExnsyzLutg7Hzp0SKGhoVq3bp369u2r8vJydejQQUuWLNFvf/tbSdLOnTvVpUsX5efnq2fPnvr4449122236cCBAwoLC5MkzZs3T0899ZQOHTokX19fPfXUU1q1apW+/PJL12MNHz5cZWVlysrKuqDZKioqFBQUpPLyctnt9ot9iv9T9NOrGm3fl8q+GSmeHqFBcCwAwHwX+u/3rzoHpry8XJIUEhIiSSooKNDp06eVlJTkWhMTE6OOHTsqPz9fkpSfn6/rrrvOFS+SlJycrIqKCu3YscO15qf7OLvm7D7qUl1drYqKCrcLAABoni46YGprazVx4kT95je/0bXXXitJcjqd8vX1VXBwsNvasLAwOZ1O15qfxsvZ7We3nW9NRUWFTpw4Uec8mZmZCgoKcl0iIyMv9qkBAIAm7qIDJi0tTV9++aWWLl3akPNctIyMDJWXl7su+/fv9/RIAACgkfhczJ0mTJiglStXKi8vT5dffrnrdofDoVOnTqmsrMztVZiSkhI5HA7Xms2bN7vt7+ynlH665uefXCopKZHdblfr1q3rnMnPz09+fn4X83QAAIBh6vUKjGVZmjBhgj788EOtXbtWV1xxhdv2+Ph4tWrVSjk5Oa7bdu3apeLiYiUmJkqSEhMTtX37dpWWlrrWZGdny263KzY21rXmp/s4u+bsPgAAQMtWr1dg0tLStGTJEv3zn/9U27ZtXeesBAUFqXXr1goKCtLo0aOVnp6ukJAQ2e12PfbYY0pMTFTPnj0lSQMHDlRsbKweeOABzZw5U06nU88884zS0tJcr6CMGzdOr776qp588kn97ne/09q1a/Xuu+9q1SrzP2UCAAB+vXq9AvP666+rvLxc/fr1U3h4uOuybNky15rZs2frtttuU2pqqvr27SuHw6EPPvjAtd3b21srV66Ut7e3EhMTdf/992vkyJGaPn26a80VV1yhVatWKTs7W3FxcfrrX/+q+fPnKzk5uQGeMgAAMN2v+h6YpozvgblwzeW7RzgWAGC+S/I9MAAAAJ5AwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACM4+PpAQA0P9FPr/L0CA1i34wUT48A4Bx4BQYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAceodMHl5eRoyZIgiIiJks9m0fPlyt+0PPvigbDab22XQoEFua44ePaoRI0bIbrcrODhYo0ePVmVlpduaoqIi9enTR/7+/oqMjNTMmTPr/+wAAECzVO+AqaqqUlxcnObOnXvONYMGDdLBgwddl3/84x9u20eMGKEdO3YoOztbK1euVF5ensaOHevaXlFRoYEDByoqKkoFBQV64YUX9Nxzz+nNN9+s77gAAKAZ8qnvHQYPHqzBgwefd42fn58cDked277++mtlZWVpy5Yt6tGjhyTplVde0a233qoXX3xRERERWrx4sU6dOqUFCxbI19dX11xzjQoLCzVr1iy30Pmp6upqVVdXu65XVFTU96kBAABDNMo5MLm5uQoNDVXnzp01fvx4HTlyxLUtPz9fwcHBrniRpKSkJHl5eWnTpk2uNX379pWvr69rTXJysnbt2qVjx47V+ZiZmZkKCgpyXSIjIxvjqQEAgCagwQNm0KBBevvtt5WTk6O//OUvWrdunQYPHqyamhpJktPpVGhoqNt9fHx8FBISIqfT6VoTFhbmtubs9bNrfi4jI0Pl5eWuy/79+xv6qQEAgCai3m8h/S/Dhw93/fm6665T165dddVVVyk3N1cDBgxo6Idz8fPzk5+fX6PtHwAANB2N/jHqK6+8Uu3bt9e3334rSXI4HCotLXVbc+bMGR09etR13ozD4VBJSYnbmrPXz3VuDQAAaDkaPWC+//57HTlyROHh4ZKkxMRElZWVqaCgwLVm7dq1qq2tVUJCgmtNXl6eTp8+7VqTnZ2tzp0767LLLmvskQEAQBNX74CprKxUYWGhCgsLJUl79+5VYWGhiouLVVlZqSlTpmjjxo3at2+fcnJyNHToUF199dVKTk6WJHXp0kWDBg3SmDFjtHnzZm3YsEETJkzQ8OHDFRERIUm677775Ovrq9GjR2vHjh1atmyZ5syZo/T09IZ75gAAwFj1DpitW7eqW7du6tatmyQpPT1d3bp109SpU+Xt7a2ioiLdfvvt6tSpk0aPHq34+HitX7/e7fyUxYsXKyYmRgMGDNCtt96q3r17u33HS1BQkNasWaO9e/cqPj5ekyZN0tSpU8/5EWoAANCy1Psk3n79+smyrHNu/+STT/7nPkJCQrRkyZLzrunatavWr19f3/EAAEALwG8hAQAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOD6eHgAA0Hiin17l6REaxL4ZKZ4eAU0Mr8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDgEDAAAMA4BAwAAjEPAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxDwAAAAOMQMAAAwDg+nh4AAICWIPrpVZ4eoUHsm5Hi6REk8QoMAAAwEAEDAACMQ8AAAADjEDAAAMA4BAwAADAOAQMAAIxT74DJy8vTkCFDFBERIZvNpuXLl7tttyxLU6dOVXh4uFq3bq2kpCTt3r3bbc3Ro0c1YsQI2e12BQcHa/To0aqsrHRbU1RUpD59+sjf31+RkZGaOXNm/Z8dAABoluodMFVVVYqLi9PcuXPr3D5z5ky9/PLLmjdvnjZt2qQ2bdooOTlZJ0+edK0ZMWKEduzYoezsbK1cuVJ5eXkaO3asa3tFRYUGDhyoqKgoFRQU6IUXXtBzzz2nN9988yKeIgAAaG7q/UV2gwcP1uDBg+vcZlmWXnrpJT3zzDMaOnSoJOntt99WWFiYli9fruHDh+vrr79WVlaWtmzZoh49ekiSXnnlFd1666168cUXFRERocWLF+vUqVNasGCBfH19dc0116iwsFCzZs1yCx0AANAyNeg5MHv37pXT6VRSUpLrtqCgICUkJCg/P1+SlJ+fr+DgYFe8SFJSUpK8vLy0adMm15q+ffvK19fXtSY5OVm7du3SsWPH6nzs6upqVVRUuF0AAEDz1KAB43Q6JUlhYWFut4eFhbm2OZ1OhYaGum338fFRSEiI25q69vHTx/i5zMxMBQUFuS6RkZG//gkBAIAmqdl8CikjI0Pl5eWuy/79+z09EgAAaCQNGjAOh0OSVFJS4nZ7SUmJa5vD4VBpaanb9jNnzujo0aNua+rax08f4+f8/Pxkt9vdLgAAoHlq0IC54oor5HA4lJOT47qtoqJCmzZtUmJioiQpMTFRZWVlKigocK1Zu3atamtrlZCQ4FqTl5en06dPu9ZkZ2erc+fOuuyyyxpyZAAAYKB6B0xlZaUKCwtVWFgo6ccTdwsLC1VcXCybzaaJEyfq+eef14oVK7R9+3aNHDlSERERGjZsmCSpS5cuGjRokMaMGaPNmzdrw4YNmjBhgoYPH66IiAhJ0n333SdfX1+NHj1aO3bs0LJlyzRnzhylp6c32BMHAADmqvfHqLdu3aqbb77Zdf1sVIwaNUoLFy7Uk08+qaqqKo0dO1ZlZWXq3bu3srKy5O/v77rP4sWLNWHCBA0YMEBeXl5KTU3Vyy+/7NoeFBSkNWvWKC0tTfHx8Wrfvr2mTp3KR6gBAICkiwiYfv36ybKsc2632WyaPn26pk+ffs41ISEhWrJkyXkfp2vXrlq/fn19xwMAAC1As/kUEgAAaDkIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcRo8YJ577jnZbDa3S0xMjGv7yZMnlZaWpnbt2ikwMFCpqakqKSlx20dxcbFSUlIUEBCg0NBQTZkyRWfOnGnoUQEAgKF8GmOn11xzjT799NP/PojPfx/miSee0KpVq/Tee+8pKChIEyZM0J133qkNGzZIkmpqapSSkiKHw6HPP/9cBw8e1MiRI9WqVSv9+c9/boxxAQCAYRolYHx8fORwOH5xe3l5uf72t79pyZIl6t+/vyTprbfeUpcuXbRx40b17NlTa9as0VdffaVPP/1UYWFhuv766/XHP/5RTz31lJ577jn5+vo2xsgAAMAgjXIOzO7duxUREaErr7xSI0aMUHFxsSSpoKBAp0+fVlJSkmttTEyMOnbsqPz8fElSfn6+rrvuOoWFhbnWJCcnq6KiQjt27DjnY1ZXV6uiosLtAgAAmqcGD5iEhAQtXLhQWVlZev3117V371716dNHx48fl9PplK+vr4KDg93uExYWJqfTKUlyOp1u8XJ2+9lt55KZmamgoCDXJTIysmGfGAAAaDIa/C2kwYMHu/7ctWtXJSQkKCoqSu+++65at27d0A/nkpGRofT0dNf1iooKIgYAgGaq0T9GHRwcrE6dOunbb7+Vw+HQqVOnVFZW5rampKTEdc6Mw+H4xaeSzl6v67yas/z8/GS3290uAACgeWr0gKmsrNSePXsUHh6u+Ph4tWrVSjk5Oa7tu3btUnFxsRITEyVJiYmJ2r59u0pLS11rsrOzZbfbFRsb29jjAgAAAzT4W0iTJ0/WkCFDFBUVpQMHDmjatGny9vbWvffeq6CgII0ePVrp6ekKCQmR3W7XY489psTERPXs2VOSNHDgQMXGxuqBBx7QzJkz5XQ69cwzzygtLU1+fn4NPS4AADBQgwfM999/r3vvvVdHjhxRhw4d1Lt3b23cuFEdOnSQJM2ePVteXl5KTU1VdXW1kpOT9dprr7nu7+3trZUrV2r8+PFKTExUmzZtNGrUKE2fPr2hRwUAAIZq8IBZunTpebf7+/tr7ty5mjt37jnXREVFafXq1Q09GgAAaCb4LSQAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADGIWAAAIBxCBgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYJwmHTBz585VdHS0/P39lZCQoM2bN3t6JAAA0AQ02YBZtmyZ0tPTNW3aNH3xxReKi4tTcnKySktLPT0aAADwsCYbMLNmzdKYMWP00EMPKTY2VvPmzVNAQIAWLFjg6dEAAICH+Xh6gLqcOnVKBQUFysjIcN3m5eWlpKQk5efn13mf6upqVVdXu66Xl5dLkioqKhp11trqHxp1/5dCY/8dXSoci6ajORwLqXkcD45F08GxqN/+Lcs677omGTCHDx9WTU2NwsLC3G4PCwvTzp0767xPZmam/u///u8Xt0dGRjbKjM1J0EuengBncSyaFo5H08GxaDou1bE4fvy4goKCzrm9SQbMxcjIyFB6errrem1trY4ePap27drJZrN5cLKLV1FRocjISO3fv192u93T47R4HI+mg2PRdHAsmo7mciwsy9Lx48cVERFx3nVNMmDat28vb29vlZSUuN1eUlIih8NR5338/Pzk5+fndltwcHBjjXhJ2e12o//H2NxwPJoOjkXTwbFoOprDsTjfKy9nNcmTeH19fRUfH6+cnBzXbbW1tcrJyVFiYqIHJwMAAE1Bk3wFRpLS09M1atQo9ejRQzfeeKNeeuklVVVV6aGHHvL0aAAAwMOabMDcc889OnTokKZOnSqn06nrr79eWVlZvzixtznz8/PTtGnTfvHWGDyD49F0cCyaDo5F09HSjoXN+l+fUwIAAGhimuQ5MAAAAOdDwAAAAOMQMAAAwDgEDAAAMA4BAwD4VfgsCDyhyX6MGgBgBj8/P23btk1dunTx9CgtyuHDh7VgwQLl5+fL6XRKkhwOh3r16qUHH3xQHTp08PCEjYuPUTcxX3/9tTZu3KjExETFxMRo586dmjNnjqqrq3X//ferf//+nh4Rkvbv369p06ZpwYIFnh6lRThx4oQKCgoUEhKi2NhYt20nT57Uu+++q5EjR3poupbjp78391Nz5szR/fffr3bt2kmSZs2adSnHapG2bNmi5ORkBQQEKCkpyfUdaSUlJcrJydEPP/ygTz75RD169PDwpI2HgGlCsrKyNHToUAUGBuqHH37Qhx9+qJEjRyouLk61tbVat26d1qxZQ8Q0Adu2bVP37t1VU1Pj6VGavW+++UYDBw5UcXGxbDabevfuraVLlyo8PFzSj//BjoiI4FhcAl5eXoqLi/vF78ytW7dOPXr0UJs2bWSz2bR27VrPDNiC9OzZU3FxcZo3b94vfrDYsiyNGzdORUVFys/P99CEjY+AaUJ69eql/v376/nnn9fSpUv16KOPavz48frTn/4k6cdf3C4oKNCaNWs8PGnzt2LFivNu//e//61Jkybxj+YlcMcdd+j06dNauHChysrKNHHiRH311VfKzc1Vx44dCZhLaMaMGXrzzTc1f/58t/8j1apVK23btu0Xr46h8bRu3Vr/+te/FBMTU+f2nTt3qlu3bjpx4sQlnuwSstBk2O12a/fu3ZZlWVZNTY3l4+NjffHFF67t27dvt8LCwjw1Xotis9ksLy8vy2aznfPi5eXl6TFbhNDQUKuoqMh1vba21ho3bpzVsWNHa8+ePZbT6eRYXEKbN2+2OnXqZE2aNMk6deqUZVmW5ePjY+3YscPDk7Us0dHR1qJFi865fdGiRVZUVNSlG8gD+BRSE3P2pUAvLy/5+/u7/aR427ZtVV5e7qnRWpTw8HB98MEHqq2trfPyxRdfeHrEFuPEiRPy8fnv5w1sNptef/11DRkyRDfddJO++eYbD07X8txwww0qKCjQoUOH1KNHD3355Ze/eAsDjW/y5MkaO3asHn/8ca1YsUKbNm3Spk2btGLFCj3++OMaN26cnnzySU+P2aj4FFITEh0drd27d+uqq66SJOXn56tjx46u7cXFxa73/dG44uPjVVBQoKFDh9a53Waz8dHRSyQmJkZbt279xSdcXn31VUnS7bff7omxWrTAwEAtWrRIS5cuVVJSEm/feUBaWprat2+v2bNn67XXXnMdA29vb8XHx2vhwoW6++67PTxl4+IcmCZk3rx5ioyMVEpKSp3bf//736u0tFTz58+/xJO1POvXr1dVVZUGDRpU5/aqqipt3bpVN9100yWerOXJzMzU+vXrtXr16jq3P/roo5o3b55qa2sv8WSQpO+//14FBQVKSkpSmzZtPD1Oi3T69GkdPnxYktS+fXu1atXKwxNdGgQMAAAwDufAAAAA4xAwAADAOAQMAAAwDgEDAACMQ8AAMEJubq5sNpvKyso8PQqAJoCAAVAvhw4d0vjx49WxY0f5+fnJ4XAoOTlZGzZsaLDH6NevnyZOnOh2W69evXTw4EG3L3f0lAcffFDDhg3z9BhAi8YX2QGol9TUVJ06dUqLFi3SlVde6fr12yNHjjTq4/r6+srhcDTqYwAwiEd/yACAUY4dO2ZJsnJzc8+7ZvTo0Vb79u2ttm3bWjfffLNVWFjo2j5t2jQrLi7Oevvtt62oqCjLbrdb99xzj1VRUWFZlmWNGjXKkuR22bt3r/XZZ59Zkqxjx45ZlmVZb731lhUUFGR99NFHVqdOnazWrVtbqampVlVVlbVw4UIrKirKCg4Oth577DHrzJkzrsc/efKkNWnSJCsiIsIKCAiwbrzxRuuzzz5zbT+736ysLCsmJsZq06aNlZycbB04cMA1/8/n++n9AVwavIUE4IIFBgYqMDBQy5cvV3V1dZ1r7rrrLpWWlurjjz9WQUGBunfvrgEDBujo0aOuNXv27NHy5cu1cuVKrVy5UuvWrdOMGTMkSXPmzFFiYqLGjBmjgwcP6uDBg4qMjKzzsX744Qe9/PLLWrp0qbKyspSbm6s77rhDq1ev1urVq/XOO+/ojTfe0Pvvv++6z4QJE5Sfn6+lS5eqqKhId911lwYNGqTdu3e77ffFF1/UO++8o7y8PBUXF2vy5MmSfvwNmrvvvluDBg1yzderV69f/XcLoJ48XVAAzPL+++9bl112meXv72/16tXLysjIsLZt22ZZlmWtX7/estvt1smTJ93uc9VVV1lvvPGGZVk/voIREBDgesXFsixrypQpVkJCguv6TTfdZD3++ONu+6jrFRhJ1rfffuta88gjj1gBAQHW8ePHXbclJydbjzzyiGVZlvXdd99Z3t7e1n/+8x+3fQ8YMMDKyMg4537nzp3r9kvwo0aNsoYOHXpBf18AGgfnwACol9TUVKWkpGj9+vXauHGjPv74Y82cOVPz589XVVWVKisr1a5dO7f7nDhxQnv27HFdj46OVtu2bV3Xw8PDVVpaWu9ZAgICXD9+KklhYWGKjo5WYGCg221n9719+3bV1NSoU6dObvuprq52m/nn+73Y+QA0HgIGQL35+/vrlltu0S233KJnn31WDz/8sKZNm6ZHH31U4eHhys3N/cV9goODXX/++Y/N2Wy2i/oxxrr2c759V1ZWytvbWwUFBfL29nZb99PoqWsfFj8bBzQpBAyAXy02NlbLly9X9+7d5XQ65ePjo+jo6Iven6+vr2pqahpuwP+vW7duqqmpUWlpqfr06XPR+2ms+QBcOE7iBXDBjhw5ov79++vvf/+7ioqKtHfvXr333nuaOXOmhg4dqqSkJCUmJmrYsGFas2aN9u3bp88//1x/+MMftHXr1gt+nOjoaG3atEn79u3T4cOHL+rVmbp06tRJI0aM0MiRI/XBBx9o79692rx5szIzM7Vq1ap6zVdUVKRdu3bp8OHDOn36dIPMB+DCETAALlhgYKASEhI0e/Zs9e3bV9dee62effZZjRkzRq+++qpsNptWr16tvn376qGHHlKnTp00fPhwfffddwoLC7vgx5k8ebK8vb0VGxurDh06qLi4uMGew1tvvaWRI0dq0qRJ6ty5s4YNG6YtW7aoY8eOF7yPMWPGqHPnzurRo4c6dOjQoF/iB+DC2Cze2AUAAIbhFRgAAGAcAgYAABiHgAEAAMYhYAAAgHEIGAAAYBwCBgAAGIeAAQAAxiFgAACAcQgYAABgHAIGAAAYh4ABAADG+X8ebKqAB2W2fgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Sentiment'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 512\n",
    "num_samples = len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 512)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokens = tokenizer(df['Phrase'].tolist(), padding='max_length', truncation=True, max_length=seq_len, add_special_tokens=True, return_tensors=\"np\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8529, 512), (8529, 512))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids'].shape, tokens['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 101,  138, 1326, ...,    0,    0,    0],\n",
       "       [ 101, 1188, 3589, ...,    0,    0,    0],\n",
       "       [ 101, 2431, 3899, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 101,  118,  149, ...,    0,    0,    0],\n",
       "       [ 101, 1109, 2523, ...,    0,    0,    0],\n",
       "       [ 101, 1109, 1273, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open('../data/movie-xids.npy', 'wb') as f:\n",
    "    np.save(f, tokens['input_ids'])\n",
    "with open('../data/movie-xmask.npy', 'wb') as f:\n",
    "    np.save(f, tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## One-hot encode the labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "labels = enc.fit_transform(df['Sentiment'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8529, 5)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/movie-labels.npy', 'wb') as f:\n",
    "    np.save(f, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/movie-labels.npy', 'rb') as f:\n",
    "    labels = np.load(f)\n",
    "\n",
    "with open('../data/movie-xids.npy', 'rb') as f:\n",
    "    xids = np.load(f)\n",
    "\n",
    "with open('../data/movie-xmask.npy', 'rb') as f:\n",
    "    xmask = np.load(f)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8529, 512), (8529, 512), (8529, 5))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xids.shape, xmask.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((xids, xmask, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(512,), dtype=tf.int32, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(input_ids, masks, labels):\n",
    "    return {'input_ids': input_ids, 'attention_mask': masks}, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(map_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(512,), dtype=tf.int32, name=None)}, TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, val_data) = dataset.take(int(split*num_samples)), dataset.skip(int(split*num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=({'input_ids': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(16, 512), dtype=tf.int32, name=None)}, TensorSpec(shape=(16, 5), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819f13f8f5c94f1e89f3d774386e105b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFAutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108310272 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108310272 (413.17 MB)\n",
      "Trainable params: 108310272 (413.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two inputs\n",
    "input_ids = tf.keras.layers.Input(shape=(seq_len,), name='input_ids', dtype='int32')\n",
    "mask = tf.keras.layers.Input(shape=(seq_len,), name='attention_mask', dtype='int32')\n",
    "\n",
    "# bert layer\n",
    "embeddings = bert.bert(input_ids, attention_mask=mask)[1]\n",
    "\n",
    "# classifier\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(embeddings)\n",
    "y = tf.keras.layers.Dense(5, activation='softmax', name='outputs')(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[input_ids, mask], outputs=[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 512)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 512)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)      TFBaseModelOutputWithPooli   1083102   ['input_ids[0][0]',           \n",
      "                             ngAndCrossAttentions(last_   72         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 512, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 787456    ['bert[0][1]']                \n",
      "                                                                                                  \n",
      " outputs (Dense)             (None, 5)                    5125      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109102853 (416.19 MB)\n",
      "Trainable params: 109102853 (416.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 512)]                0         []                            \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer  [(None, 512)]                0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)      TFBaseModelOutputWithPooli   1083102   ['input_ids[0][0]',           \n",
      "                             ngAndCrossAttentions(last_   72         'attention_mask[0][0]']      \n",
      "                             hidden_state=(None, 512, 7                                           \n",
      "                             68),                                                                 \n",
      "                              pooler_output=(None, 768)                                           \n",
      "                             , past_key_values=None, hi                                           \n",
      "                             dden_states=None, attentio                                           \n",
      "                             ns=None, cross_attentions=                                           \n",
      "                             None)                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 787456    ['bert[0][1]']                \n",
      "                                                                                                  \n",
      " outputs (Dense)             (None, 5)                    5125      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109102853 (416.19 MB)\n",
      "Trainable params: 792581 (3.02 MB)\n",
      "Non-trainable params: 108310272 (413.17 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "acc = tf.keras.metrics.CategoricalAccuracy('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=[acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 11/533 [..............................] - ETA: 3:08:55 - loss: 1.6104 - accuracy: 0.2500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\NLPProjects\\notebooks\\sentiment.ipynb Cell 50\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/NLPProjects/notebooks/sentiment.ipynb#Y133sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m histry \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_data, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval_data)\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[0;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[0;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[0;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[0;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[0;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1463\u001b[0m   )\n\u001b[0;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Abhilash\\anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "histry = model.fit(train_data, epochs=3, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentiment_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
